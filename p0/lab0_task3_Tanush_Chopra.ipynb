{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-UzeCP8doGL"
      },
      "source": [
        "# Pleas read:\n",
        "\n",
        "before your start running this jupyter notebook, please click Edit > Notebook Settings and choose any of the available GPUs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPj69Ai0VJpu"
      },
      "source": [
        "## 0. Import Python Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SEsUoci9Uv5x"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import thop\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTjEJu-1VHvf"
      },
      "source": [
        "## 1. Define ResNet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    \"\"\"Initial implementation courtesy of GeeksForGeeks.\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(Block, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out += self.shortcut(x)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class DepthwiseBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(DepthwiseBlock, self).__init__()\n",
        "        self.dw1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=stride, padding=1, groups=in_channels, bias=False)\n",
        "        self.pw1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.dw2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, groups=out_channels, bias=False)\n",
        "        self.pw2 = nn.Conv2d(out_channels, out_channels, kernel_size=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.dw1(x)\n",
        "        out = self.pw1(out)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.dw2(out)\n",
        "        out = self.pw2(out)\n",
        "        out = self.bn2(out)\n",
        "        out += self.shortcut(x)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class InvertedResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, expandion=6):\n",
        "        super(InvertedResidualBlock, self).__init__()\n",
        "        self.use_shortcut = stride == 1 and in_channels == out_channels\n",
        "        exp_channels = in_channels * expandion\n",
        "        layers = []\n",
        "        if expandion != 1:\n",
        "            layers.extend([\n",
        "                nn.Conv2d(in_channels, exp_channels, kernel_size=1, bias=False),\n",
        "                nn.BatchNorm2d(exp_channels),\n",
        "                nn.ReLU6(inplace=True)\n",
        "            ])\n",
        "        dw_channels = exp_channels if expandion != 1 else in_channels\n",
        "        layers.extend([\n",
        "            nn.Conv2d(dw_channels, dw_channels, kernel_size=3, stride=stride, \n",
        "                     padding=1, groups=dw_channels, bias=False),\n",
        "            nn.BatchNorm2d(dw_channels),\n",
        "            nn.ReLU6(inplace=True)\n",
        "        ])\n",
        "        layers.extend([\n",
        "            nn.Conv2d(dw_channels, out_channels, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        ])        \n",
        "        self.conv = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_shortcut:\n",
        "            return x + self.conv(x)\n",
        "        else:\n",
        "            return self.conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "BLOCK = {\n",
        "    \"basic\": Block,\n",
        "    \"depthwise\": DepthwiseBlock,\n",
        "    \"inverted\": InvertedResidualBlock,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5D1EKsHUfjSD"
      },
      "outputs": [],
      "source": [
        "class ResNet18(nn.Module):\n",
        "    \"\"\"Initial implementation courtesy of GeeksForGeeks\"\"\"\n",
        "    def __init__(self, num_classes=10, in_channels=3, block_type='basic'):\n",
        "        super(ResNet18, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        \n",
        "        self.block = BLOCK.get(block_type)\n",
        "        assert self.block, \"Invalid block_type given. Supported types: 'basic', 'depthwise', 'inverted'.\"\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.l1 = self._make_layer(self.block, 64, 2, stride=1)\n",
        "        self.l2 = self._make_layer(self.block, 128, 2, stride=2)\n",
        "        self.l3 = self._make_layer(self.block, 256, 2, stride=2)\n",
        "        self.l4 = self._make_layer(self.block, 512, 2, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.maxpool(out)\n",
        "\n",
        "        out = self.l1(out)\n",
        "        out = self.l2(out)\n",
        "        out = self.l3(out)\n",
        "        out = self.l4(out)\n",
        "\n",
        "        out = self.avgpool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDG9sEPOXjYa"
      },
      "source": [
        "## 2. Implement training loop and test function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Qk-kH1KwXfG3"
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_loader, optimizer, epoch, scheduler):\n",
        "    losses = []\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(train_loader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y_hat = model(X)\n",
        "        loss = F.nll_loss(F.log_softmax(y_hat, dim=1), y.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch % 100 == 0:\n",
        "            losses.append(loss.item())\n",
        "    scheduler.step()\n",
        "    return losses\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    accuracy = 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            output = model(X)\n",
        "            loss += F.nll_loss(F.log_softmax(output, dim=1), y.long(), reduction='sum').item()\n",
        "            predicted = F.log_softmax(output, dim=1).argmax(dim=1, keepdim=True)\n",
        "            accuracy += predicted.eq(y.view_as(predicted)).sum().item()\n",
        "\n",
        "    loss /= len(test_loader.dataset)\n",
        "    accuracy /= len(test_loader.dataset)\n",
        "\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run(\n",
        "    epochs: int,\n",
        "    device: torch.device,\n",
        "    train_dl: torch.utils.data.DataLoader,\n",
        "    val_dl: torch.utils.data.DataLoader,\n",
        "    test_dl: torch.utils.data.DataLoader,\n",
        "    model: torch.nn.Module,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    scheduler: torch.optim.lr_scheduler.StepLR,\n",
        "):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    best = float('inf')\n",
        "    patience = 10\n",
        "    stop = 0\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        loss = train(model, device, train_dl, optimizer, epoch, scheduler)\n",
        "        train_losses.append(sum(loss) / len(loss))\n",
        "        val_loss, val_acc = test(model, device, val_dl)\n",
        "        val_losses.append(val_loss)\n",
        "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
        "        if val_loss < best:\n",
        "            best = val_loss\n",
        "            stop = 0\n",
        "        else:\n",
        "            stop += 1\n",
        "        if stop >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "    test_loss, test_accuracy = test(model, device, test_dl)\n",
        "    return train_losses, val_losses, test_loss, test_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQMOatS9SHae"
      },
      "source": [
        "# 3. CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_naJr-Y0MYyY"
      },
      "outputs": [],
      "source": [
        "CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)\n",
        "CIFAR10_STD = (0.2470, 0.2435, 0.2616)\n",
        "TRAIN_TRANSFORM = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),    \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD),\n",
        "])\n",
        "TEST_TRANSFORM = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "CIFAR10_TRAIN = datasets.CIFAR10(\"./\", train=True, transform=TRAIN_TRANSFORM, download=True)\n",
        "CIFAR10_TEST = datasets.CIFAR10(\"./\", train=False, transform=TEST_TRANSFORM, download=True)\n",
        "\n",
        "train_size = int(0.8 * len(CIFAR10_TRAIN))\n",
        "val_size = len(CIFAR10_TRAIN) - train_size\n",
        "\n",
        "CIFAR10_TRAIN, CIFAR10_VALIDATION = torch.utils.data.random_split(CIFAR10_TRAIN, [train_size, val_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch = 256\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_dl = torch.utils.data.DataLoader(CIFAR10_TRAIN, batch_size=batch, shuffle=True)\n",
        "val_dl = torch.utils.data.DataLoader(CIFAR10_VALIDATION, batch_size=batch, shuffle=True)\n",
        "test_dl = torch.utils.data.DataLoader(CIFAR10_TEST, batch_size=batch, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Depthwise Convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "Validation Loss: 1.4029, Validation Accuracy: 0.4972\n",
            "Epoch 2/30\n",
            "Validation Loss: 1.3013, Validation Accuracy: 0.5429\n",
            "Epoch 3/30\n",
            "Validation Loss: 1.1181, Validation Accuracy: 0.5973\n",
            "Epoch 4/30\n",
            "Validation Loss: 1.0611, Validation Accuracy: 0.6247\n",
            "Epoch 5/30\n",
            "Validation Loss: 1.0055, Validation Accuracy: 0.6500\n",
            "Epoch 6/30\n",
            "Validation Loss: 0.9299, Validation Accuracy: 0.6731\n",
            "Epoch 7/30\n",
            "Validation Loss: 0.9154, Validation Accuracy: 0.6868\n",
            "Epoch 8/30\n",
            "Validation Loss: 0.9805, Validation Accuracy: 0.6633\n",
            "Epoch 9/30\n",
            "Validation Loss: 0.8730, Validation Accuracy: 0.6991\n",
            "Epoch 10/30\n",
            "Validation Loss: 0.9097, Validation Accuracy: 0.6894\n",
            "Epoch 11/30\n",
            "Validation Loss: 0.8729, Validation Accuracy: 0.6986\n",
            "Epoch 12/30\n",
            "Validation Loss: 0.8160, Validation Accuracy: 0.7166\n",
            "Epoch 13/30\n",
            "Validation Loss: 0.9176, Validation Accuracy: 0.6880\n",
            "Epoch 14/30\n",
            "Validation Loss: 0.8012, Validation Accuracy: 0.7205\n",
            "Epoch 15/30\n",
            "Validation Loss: 0.7812, Validation Accuracy: 0.7273\n",
            "Epoch 16/30\n",
            "Validation Loss: 0.6274, Validation Accuracy: 0.7848\n",
            "Epoch 17/30\n",
            "Validation Loss: 0.6186, Validation Accuracy: 0.7883\n",
            "Epoch 18/30\n",
            "Validation Loss: 0.6140, Validation Accuracy: 0.7873\n",
            "Epoch 19/30\n",
            "Validation Loss: 0.6057, Validation Accuracy: 0.7955\n",
            "Epoch 20/30\n",
            "Validation Loss: 0.5994, Validation Accuracy: 0.7938\n",
            "Epoch 21/30\n",
            "Validation Loss: 0.5927, Validation Accuracy: 0.7984\n",
            "Epoch 22/30\n",
            "Validation Loss: 0.5958, Validation Accuracy: 0.7964\n",
            "Epoch 23/30\n",
            "Validation Loss: 0.5871, Validation Accuracy: 0.8016\n",
            "Epoch 24/30\n",
            "Validation Loss: 0.5889, Validation Accuracy: 0.8016\n",
            "Epoch 25/30\n",
            "Validation Loss: 0.5849, Validation Accuracy: 0.8034\n",
            "Epoch 26/30\n",
            "Validation Loss: 0.5882, Validation Accuracy: 0.8041\n",
            "Epoch 27/30\n",
            "Validation Loss: 0.5779, Validation Accuracy: 0.8044\n",
            "Epoch 28/30\n",
            "Validation Loss: 0.5808, Validation Accuracy: 0.8014\n",
            "Epoch 29/30\n",
            "Validation Loss: 0.5877, Validation Accuracy: 0.8049\n",
            "Epoch 30/30\n",
            "Validation Loss: 0.5792, Validation Accuracy: 0.8046\n"
          ]
        }
      ],
      "source": [
        "cifar10_epochs = 30\n",
        "dw_model = ResNet18(in_channels=3, block_type=\"depthwise\").to(device)\n",
        "dw_optimizer = torch.optim.Adam(dw_model.parameters(), lr=5e-3, weight_decay=1e-4)\n",
        "dw_scheduler = torch.optim.lr_scheduler.MultiStepLR(dw_optimizer, milestones=[15, 20, 25], gamma=0.1)\n",
        "\n",
        "dw_train_losses, dw_val_losses, dw_test_loss, dw_test_accuracy = run(cifar10_epochs, device, train_dl, val_dl, test_dl, dw_model, dw_optimizer, dw_scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.4825, Test Accuracy: 0.8377\n"
          ]
        }
      ],
      "source": [
        "print(f\"Test Loss: {dw_test_loss:.4f}, Test Accuracy: {dw_test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. Inverted Residual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "Validation Loss: 1.4009, Validation Accuracy: 0.4927\n",
            "Epoch 2/30\n",
            "Validation Loss: 1.4153, Validation Accuracy: 0.5089\n",
            "Epoch 3/30\n",
            "Validation Loss: 1.0666, Validation Accuracy: 0.6221\n",
            "Epoch 4/30\n",
            "Validation Loss: 1.0816, Validation Accuracy: 0.6214\n",
            "Epoch 5/30\n",
            "Validation Loss: 1.0167, Validation Accuracy: 0.6502\n",
            "Epoch 6/30\n",
            "Validation Loss: 1.0604, Validation Accuracy: 0.6366\n",
            "Epoch 7/30\n",
            "Validation Loss: 0.9309, Validation Accuracy: 0.6655\n",
            "Epoch 8/30\n",
            "Validation Loss: 0.8762, Validation Accuracy: 0.6967\n",
            "Epoch 9/30\n",
            "Validation Loss: 0.8699, Validation Accuracy: 0.6989\n",
            "Epoch 10/30\n",
            "Validation Loss: 0.8577, Validation Accuracy: 0.7003\n",
            "Epoch 11/30\n",
            "Validation Loss: 0.8922, Validation Accuracy: 0.6916\n",
            "Epoch 12/30\n",
            "Validation Loss: 0.8163, Validation Accuracy: 0.7192\n",
            "Epoch 13/30\n",
            "Validation Loss: 0.8520, Validation Accuracy: 0.6964\n",
            "Epoch 14/30\n",
            "Validation Loss: 0.7828, Validation Accuracy: 0.7343\n",
            "Epoch 15/30\n",
            "Validation Loss: 0.7764, Validation Accuracy: 0.7345\n",
            "Epoch 16/30\n",
            "Validation Loss: 0.5980, Validation Accuracy: 0.7963\n",
            "Epoch 17/30\n",
            "Validation Loss: 0.5814, Validation Accuracy: 0.7991\n",
            "Epoch 18/30\n",
            "Validation Loss: 0.5729, Validation Accuracy: 0.8061\n",
            "Epoch 19/30\n",
            "Validation Loss: 0.5594, Validation Accuracy: 0.8055\n",
            "Epoch 20/30\n",
            "Validation Loss: 0.5488, Validation Accuracy: 0.8064\n",
            "Epoch 21/30\n",
            "Validation Loss: 0.5365, Validation Accuracy: 0.8135\n",
            "Epoch 22/30\n",
            "Validation Loss: 0.5152, Validation Accuracy: 0.8241\n",
            "Epoch 23/30\n",
            "Validation Loss: 0.5288, Validation Accuracy: 0.8179\n",
            "Epoch 24/30\n",
            "Validation Loss: 0.5256, Validation Accuracy: 0.8171\n",
            "Epoch 25/30\n",
            "Validation Loss: 0.5303, Validation Accuracy: 0.8182\n",
            "Epoch 26/30\n",
            "Validation Loss: 0.5229, Validation Accuracy: 0.8207\n",
            "Epoch 27/30\n",
            "Validation Loss: 0.5316, Validation Accuracy: 0.8156\n",
            "Epoch 28/30\n",
            "Validation Loss: 0.5168, Validation Accuracy: 0.8247\n",
            "Epoch 29/30\n",
            "Validation Loss: 0.5130, Validation Accuracy: 0.8206\n",
            "Epoch 30/30\n",
            "Validation Loss: 0.5225, Validation Accuracy: 0.8235\n"
          ]
        }
      ],
      "source": [
        "cifar10_epochs = 30\n",
        "inv_model = ResNet18(in_channels=3, block_type=\"inverted\").to(device)\n",
        "inv_optimizer = torch.optim.Adam(inv_model.parameters(), lr=5e-3, weight_decay=1e-4)\n",
        "inv_scheduler = torch.optim.lr_scheduler.MultiStepLR(inv_optimizer, milestones=[15, 20, 25], gamma=0.1)\n",
        "\n",
        "inv_train_losses, inv_val_losses, inv_test_loss, inv_test_accuracy = run(cifar10_epochs, device, train_dl, val_dl, test_dl, inv_model, inv_optimizer, inv_scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.4199, Test Accuracy: 0.8567\n"
          ]
        }
      ],
      "source": [
        "print(f\"Test Loss: {inv_test_loss:.4f}, Test Accuracy: {inv_test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. Standard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "Validation Loss: 1.6995, Validation Accuracy: 0.3753\n",
            "Epoch 2/30\n",
            "Validation Loss: 1.3043, Validation Accuracy: 0.5352\n",
            "Epoch 3/30\n",
            "Validation Loss: 1.2936, Validation Accuracy: 0.5447\n",
            "Epoch 4/30\n",
            "Validation Loss: 1.1958, Validation Accuracy: 0.5759\n",
            "Epoch 5/30\n",
            "Validation Loss: 1.2257, Validation Accuracy: 0.5751\n",
            "Epoch 6/30\n",
            "Validation Loss: 1.0868, Validation Accuracy: 0.6233\n",
            "Epoch 7/30\n",
            "Validation Loss: 1.0952, Validation Accuracy: 0.6191\n",
            "Epoch 8/30\n",
            "Validation Loss: 0.9393, Validation Accuracy: 0.6706\n",
            "Epoch 9/30\n",
            "Validation Loss: 0.9378, Validation Accuracy: 0.6718\n",
            "Epoch 10/30\n",
            "Validation Loss: 0.9241, Validation Accuracy: 0.6776\n",
            "Epoch 11/30\n",
            "Validation Loss: 0.8648, Validation Accuracy: 0.7019\n",
            "Epoch 12/30\n",
            "Validation Loss: 0.8359, Validation Accuracy: 0.7138\n",
            "Epoch 13/30\n",
            "Validation Loss: 0.8867, Validation Accuracy: 0.6894\n",
            "Epoch 14/30\n",
            "Validation Loss: 0.7985, Validation Accuracy: 0.7246\n",
            "Epoch 15/30\n",
            "Validation Loss: 0.9639, Validation Accuracy: 0.6722\n",
            "Epoch 16/30\n",
            "Validation Loss: 0.6708, Validation Accuracy: 0.7676\n",
            "Epoch 17/30\n",
            "Validation Loss: 0.7131, Validation Accuracy: 0.7560\n",
            "Epoch 18/30\n",
            "Validation Loss: 0.7083, Validation Accuracy: 0.7556\n",
            "Epoch 19/30\n",
            "Validation Loss: 0.7086, Validation Accuracy: 0.7629\n",
            "Epoch 20/30\n",
            "Validation Loss: 0.6919, Validation Accuracy: 0.7656\n",
            "Epoch 21/30\n",
            "Validation Loss: 0.6060, Validation Accuracy: 0.7951\n",
            "Epoch 22/30\n",
            "Validation Loss: 0.5928, Validation Accuracy: 0.8070\n",
            "Epoch 23/30\n",
            "Validation Loss: 0.5907, Validation Accuracy: 0.8042\n",
            "Epoch 24/30\n",
            "Validation Loss: 0.6141, Validation Accuracy: 0.7972\n",
            "Epoch 25/30\n",
            "Validation Loss: 0.6105, Validation Accuracy: 0.7990\n",
            "Epoch 26/30\n",
            "Validation Loss: 0.5408, Validation Accuracy: 0.8201\n",
            "Epoch 27/30\n",
            "Validation Loss: 0.5631, Validation Accuracy: 0.8186\n",
            "Epoch 28/30\n",
            "Validation Loss: 0.5713, Validation Accuracy: 0.8148\n",
            "Epoch 29/30\n",
            "Validation Loss: 0.5917, Validation Accuracy: 0.8118\n",
            "Epoch 30/30\n",
            "Validation Loss: 0.5578, Validation Accuracy: 0.8193\n"
          ]
        }
      ],
      "source": [
        "cifar10_epochs = 30\n",
        "basic_model = ResNet18(in_channels=3, block_type=\"basic\").to(device)\n",
        "basic_optimizer = torch.optim.Adam(basic_model.parameters(), lr=5e-3, weight_decay=1e-4)\n",
        "basic_scheduler = torch.optim.lr_scheduler.MultiStepLR(basic_optimizer, milestones=[15, 20, 25], gamma=0.5)\n",
        "\n",
        "basic_train_losses, basic_val_losses, basic_test_loss, basic_test_accuracy = run(cifar10_epochs, device, train_dl, val_dl, test_dl, basic_model, basic_optimizer, basic_scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.4796, Test Accuracy: 0.8527\n"
          ]
        }
      ],
      "source": [
        "print(f\"Test Loss: {basic_test_loss:.4f}, Test Accuracy: {basic_test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(basic_model.state_dict(), \"basic_model.pth\")\n",
        "torch.save(dw_model.state_dict(), \"dw_model.pth\")\n",
        "torch.save(inv_model.state_dict(), \"inv_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "basic_model = ResNet18(in_channels=3, block_type=\"basic\").to(device)\n",
        "dw_model = ResNet18(in_channels=3, block_type=\"depthwise\").to(device)\n",
        "inv_model = ResNet18(in_channels=3, block_type=\"inverted\").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basic_model.load_state_dict(torch.load(\"basic_model.pth\"))\n",
        "dw_model.load_state_dict(torch.load(\"dw_model.pth\"))\n",
        "inv_model.load_state_dict(torch.load(\"inv_model.pth\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def flops(model):\n",
        "    model.eval()\n",
        "    macs, params = thop.profile(model, inputs=(torch.randn(1, 3, 32, 32).to(device),))\n",
        "    return macs, params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU6'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
          ]
        }
      ],
      "source": [
        "basic_macs, basic_params = flops(basic_model)\n",
        "dw_macs, dw_params = flops(dw_model)\n",
        "inv_macs, inv_params = flops(inv_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic Model:\n",
            "MACs: 141000192.0, Params: 11173962.0\n",
            "Depthwise Model:\n",
            "MACs: 20406784.0, Params: 1439626.0\n",
            "Inverted Model:\n",
            "MACs: 99563008.0, Params: 5901002.0\n"
          ]
        }
      ],
      "source": [
        "print(\"Basic Model:\")\n",
        "print(f\"MACs: {basic_macs}, Params: {basic_params}\")\n",
        "print(\"Depthwise Model:\")\n",
        "print(f\"MACs: {dw_macs}, Params: {dw_params}\")\n",
        "print(\"Inverted Model:\")\n",
        "print(f\"MACs: {inv_macs}, Params: {inv_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "def latency(model: torch.nn.Module, device: torch.device, input_shape=(1, 3, 32, 32),\n",
        "                    warmup: int = 50, runs: int = 100) -> dict:\n",
        "    model.eval()\n",
        "    \n",
        "    dummy = torch.randn(*input_shape, device=device)\n",
        "    assert device.type == \"cuda\", \"Latency measurement requires CUDA device\"\n",
        "    \n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
        "    \n",
        "    with torch.inference_mode():\n",
        "        for _ in range(warmup):\n",
        "            _ = model(dummy)\n",
        "    torch.cuda.synchronize()\n",
        "    \n",
        "    times = []\n",
        "    with torch.inference_mode():\n",
        "        for _ in range(runs):\n",
        "            starter.record()\n",
        "            _ = model(dummy)\n",
        "            ender.record()\n",
        "            torch.cuda.synchronize()\n",
        "            times.append(starter.elapsed_time(ender))\n",
        "    \n",
        "    avg = sum(times) / len(times)\n",
        "    p50 = sorted(times)[len(times)//2]\n",
        "    p90 = sorted(times)[int(len(times)*0.9)]\n",
        "\n",
        "    return {\"avg_ms\": avg, \"p50_ms\": p50, \"p90_ms\": p90, \"runs\": runs}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Latency (per forward pass):\n",
            "Basic ResNet-18: {'avg_ms': 1.441298553943634, 'p50_ms': 1.4417599439620972, 'p90_ms': 1.4489599466323853, 'runs': 100}\n",
            "Depthwise ResNet-18: {'avg_ms': 1.567883838415146, 'p50_ms': 1.5667519569396973, 'p90_ms': 1.5841920375823975, 'runs': 100}\n",
            "Inverted ResNet-18: {'avg_ms': 1.5076278448104858, 'p50_ms': 1.5062719583511353, 'p90_ms': 1.516543984413147, 'runs': 100}\n",
            "\n",
            "Latency (batch of images):\n",
            "Basic ResNet-18: {'avg_ms': 5.021609635353088, 'p50_ms': 5.0575361251831055, 'p90_ms': 5.238783836364746, 'runs': 100}\n",
            "Depthwise ResNet-18: {'avg_ms': 3.460281584262848, 'p50_ms': 3.4611198902130127, 'p90_ms': 3.4662399291992188, 'runs': 100}\n",
            "Inverted ResNet-18: {'avg_ms': 11.047739572525025, 'p50_ms': 11.040767669677734, 'p90_ms': 11.084799766540527, 'runs': 100}\n"
          ]
        }
      ],
      "source": [
        "input_shape = (1, 3, 32, 32)\n",
        "\n",
        "basic_latency_single = latency(basic_model, device, input_shape=input_shape)\n",
        "dw_latency_single = latency(dw_model, device, input_shape=input_shape)\n",
        "inv_latency_single = latency(inv_model, device, input_shape=input_shape)\n",
        "\n",
        "basic_latency_batched = latency(basic_model, device, input_shape=(batch, 3, 32, 32))\n",
        "dw_latency_batched = latency(dw_model, device, input_shape=(batch, 3, 32, 32))\n",
        "inv_latency_batched = latency(inv_model, device, input_shape=(batch, 3, 32, 32))\n",
        "\n",
        "print(\"Latency (per forward pass):\")\n",
        "print(\"Basic ResNet-18:\", basic_latency_single)\n",
        "print(\"Depthwise ResNet-18:\", dw_latency_single)\n",
        "print(\"Inverted ResNet-18:\", inv_latency_single)\n",
        "\n",
        "print(\"\\nLatency (batch of images):\")\n",
        "print(\"Basic ResNet-18:\", basic_latency_batched)\n",
        "print(\"Depthwise ResNet-18:\", dw_latency_batched)\n",
        "print(\"Inverted ResNet-18:\", inv_latency_batched)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
